{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc6c53f2-21a2-4618-b7a1-23914f4a8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffca5e11-5348-4640-a14b-145f056c44df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load the data (Ensure your dataframe is loaded into df)\n",
    "df=pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b574c61-8f82-4f53-9488-a83e2ec16b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset: 50000\n",
      "Number of duplicate rows: 418\n",
      "Missing values in 'review' column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initial Data Inspection\n",
    "print(f\"Number of rows in dataset: {len(df)}\")\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Missing values in 'review' column: {df['review'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75855f17-79b6-4054-8eac-8a77df4b2880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Drop missing or duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06f165be-e525-40fc-b718-8c55ef01a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "Missing values in 'review' column: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Missing values in 'review' column: {df['review'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a10879-842e-4912-a08e-8a98beff0929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49582 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     49582 non-null  object\n",
      " 1   sentiment  49582 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548e57b8-e25d-4e3b-80b0-20b4b25064cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Label Encoder for target value: positive, negative\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caea935e-31ee-49c8-bbc7-d0d6f3de5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = encoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c01902e-e678-4acd-a0ea-77de1588eccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2a3503-5cda-4f61-abf0-04068fa61a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    24884\n",
       "0    24698\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0afcc35-29b6-4677-9105-179e2e0ae5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:10000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81c6382c-222c-4223-875f-a8ba25cb1383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b3216c3-761e-42af-b5bd-2b3a02936936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "028bd423-c957-457f-be45-5826043b8059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 0 to 10016\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     10000 non-null  object\n",
      " 1   sentiment  10000 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 195.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c56ca472-0871-41eb-b26a-944cea9069b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c6af12a-b4c3-432b-8662-92da03fa5b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91867\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91867\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Create an instance of PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def transform_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = nltk.word_tokenize(text)  # Tokenize the text\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():  # Keep alphanumeric tokens\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        # Remove stopwords and punctuation\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "            \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        # Apply stemming\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    return \" \".join(y)  # Return the processed text as a single string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a411bff-19e4-4ff5-aa84-aa423bd2e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_repeated_chars(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Step 1: Remove non-alphabetic characters\n",
    "    text = text.strip()\n",
    "    # Replace 4 or more consecutive repeating characters with just one occurrence\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac0cdcce-5be9-48dd-9130-b12ece602021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zizpzziz'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_repeated_chars('zzzzzizzzzpzzizzzz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb40bc6c-154a-4309-bc15-797e94f21bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_review'] = df['review'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b8c1da4-cd90-4816-a6a5-e17ce1354398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>transformed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>one review mention watch 1 oz episod hook righ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonder littl product br br film techniqu fashi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...          1   \n",
       "1  A wonderful little production. <br /><br />The...          1   \n",
       "2  I thought this was a wonderful way to spend ti...          1   \n",
       "3  Basically there's a family where a little boy ...          0   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1   \n",
       "\n",
       "                                  transformed_review  \n",
       "0  one review mention watch 1 oz episod hook righ...  \n",
       "1  wonder littl product br br film techniqu fashi...  \n",
       "2  thought wonder way spend time hot summer weeke...  \n",
       "3  basic famili littl boy jake think zombi closet...  \n",
       "4  petter mattei love time money visual stun film...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d458dfc-bfb0-4075-886f-c678b83b786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_transformed_review'] = df['transformed_review'].apply(clean_repeated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2063af13-0029-4fac-9037-e2754a2f9876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>transformed_review</th>\n",
       "      <th>new_transformed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>one review mention watch 1 oz episod hook righ...</td>\n",
       "      <td>one review mention watch  oz episod hook right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonder littl product br br film techniqu fashi...</td>\n",
       "      <td>wonder littl product br br film techniqu fashi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...          1   \n",
       "1  A wonderful little production. <br /><br />The...          1   \n",
       "2  I thought this was a wonderful way to spend ti...          1   \n",
       "3  Basically there's a family where a little boy ...          0   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1   \n",
       "\n",
       "                                  transformed_review  \\\n",
       "0  one review mention watch 1 oz episod hook righ...   \n",
       "1  wonder littl product br br film techniqu fashi...   \n",
       "2  thought wonder way spend time hot summer weeke...   \n",
       "3  basic famili littl boy jake think zombi closet...   \n",
       "4  petter mattei love time money visual stun film...   \n",
       "\n",
       "                              new_transformed_review  \n",
       "0  one review mention watch  oz episod hook right...  \n",
       "1  wonder littl product br br film techniqu fashi...  \n",
       "2  thought wonder way spend time hot summer weeke...  \n",
       "3  basic famili littl boy jake think zombi closet...  \n",
       "4  petter mattei love time money visual stun film...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "230c56a3-eccc-47df-af18-36945da556d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset \n",
    "#train dataset\n",
    "X_train=df.new_transformed_review[:8000]\n",
    "#test dataset\n",
    "X_test=df.new_transformed_review[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e73c3816-fe5b-4fcd-96f5-16f63034f4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (8000, 1344973)\n",
      "BOW_cv_test: (2000, 1344973)\n"
     ]
    }
   ],
   "source": [
    "# Bow\n",
    "#Count vectorizer for bag of words\n",
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "X_cv_train=cv.fit_transform(X_train)\n",
    "#transformed test reviews\n",
    "X_cv_test=cv.transform(X_test)\n",
    "print('BOW_cv_train:',X_cv_train.shape)\n",
    "print('BOW_cv_test:',X_cv_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd0b63cc-ab0b-4cbe-ad7e-19b2f293bc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa' 'aa date' 'aa date aa' 'aa doctor' 'aa doctor miracul' 'aag come'\n",
      " 'aag come anywher' 'aag fire' 'aag make' 'aag make cost' 'aag pardey'\n",
      " 'aag pardey par' 'aag ramu' 'aag ramu ambiti' 'aaip' 'aaip either'\n",
      " 'aaip either good' 'aak' 'aak gag' 'aaliyah actual']\n"
     ]
    }
   ],
   "source": [
    "# To get feature names (vocabulary words)\n",
    "vocab = cv.get_feature_names_out()\n",
    "print(vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cabc759-f6b0-48a0-94c4-2093f0028fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1344973"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "407b183b-1545-47e9-8a0a-1d160019a379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (8000, 10000)\n",
      "Tfidf_test: (2000, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Tfidf Vectorization\n",
    "tf = TfidfVectorizer(max_features=10000, ngram_range=(1, 3))\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_tf_train = tf.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same vocabulary as train data)\n",
    "X_tf_test = tf.transform(X_test)\n",
    "\n",
    "# Display the shapes of the resulting sparse matrices\n",
    "print('Tfidf_train:', X_tf_train.shape)\n",
    "print('Tfidf_test:', X_tf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08ffcbb9-c9b2-4a57-8be3-24843901a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset \n",
    "#train dataset\n",
    "y_train=df.sentiment[:8000]\n",
    "#test dataset\n",
    "y_test=df.sentiment[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03fe9328-3037-4bb4-843d-effa51d5da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f59470ef-53fc-41ca-9ef9-27cb3e4bd2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Train the Logistic Regression model\n",
    "cv_model = LogisticRegression(max_iter=1000)  # max_iter set to ensure convergence\n",
    "cv_model.fit(X_cv_train, y_train)  # Fit on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77c8bebb-4395-41d0-aeee-c4fb26740ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "cv_y_pred = cv_model.predict(X_cv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "03d8ff1d-5d49-4176-a758-6d191f392b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy on Test Data:\", accuracy_score(y_test, cv_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "62f47c5a-0b98-46fa-bced-7180b575be20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogR - Precision: 0.6549755301794453\n"
     ]
    }
   ],
   "source": [
    "print(\"LogR - Precision:\", precision_score(y_test, cv_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "193d3d9f-4732-481b-a3ec-5860c796b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Train the Logistic Regression model\n",
    "tf_model = LogisticRegression(max_iter=1000)  # max_iter set to ensure convergence\n",
    "tf_model.fit(X_tf_train, y_train)  # Fit on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aef85702-fcf6-4c38-9810-4aa1e4d1c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "tf_y_pred = tf_model.predict(X_tf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e37b199e-cca8-4117-a703-d80bd9d6e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.8655\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Test Data:\", accuracy_score(y_test, tf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "74fa77d2-374b-4d79-83eb-228e9b3f7750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogR - Precision: 0.8560677328316086\n"
     ]
    }
   ],
   "source": [
    "print(\"LogR - Precision:\", precision_score(y_test, tf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f4ba887-c75a-4f50-a67f-2e0c5fc356bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "447a9ee9-ebf4-434e-94f2-007f995af6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultinomialNB - Accuracy: 0.847\n",
      "MultinomialNB - Precision: 0.835820895522388\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X_tf_train, y_train)\n",
    "mnb_y_pred = mnb_model.predict(X_tf_test)\n",
    "print(\"\\nMultinomialNB - Accuracy:\", accuracy_score(y_test, mnb_y_pred))\n",
    "print(\"MultinomialNB - Precision:\", precision_score(y_test, mnb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8128a7f3-9525-4467-a122-d292d4b40c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BernoulliNB - Accuracy: 0.8485\n",
      "BernoulliNB - Precision: 0.83690587138863\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes\n",
    "bnb_model = BernoulliNB()\n",
    "bnb_model.fit(X_tf_train, y_train)\n",
    "bnb_y_pred = bnb_model.predict(X_tf_test)\n",
    "print(\"\\nBernoulliNB - Accuracy:\", accuracy_score(y_test, bnb_y_pred))\n",
    "print(\"BernoulliNB - Precision:\", precision_score(y_test, bnb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0253088f-c51c-4b7e-adbc-e9bc552e2d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GaussianNB - Accuracy: 0.7885\n",
      "GaussianNB - Precision: 0.7874165872259294\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes (convert sparse matrix to dense for GaussianNB)\n",
    "gnb_model = GaussianNB()\n",
    "X_tf_train_dense = X_tf_train.toarray()  # Convert to dense format\n",
    "X_tf_test_dense = X_tf_test.toarray()    # Convert to dense format\n",
    "gnb_model.fit(X_tf_train_dense, y_train)\n",
    "gnb_y_pred = gnb_model.predict(X_tf_test_dense)\n",
    "print(\"\\nGaussianNB - Accuracy:\", accuracy_score(y_test, gnb_y_pred))\n",
    "print(\"GaussianNB - Precision:\", precision_score(y_test, gnb_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "af81e13c-4845-43d1-bcf9-ee9ab2680c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf_vectorizer.pkl']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tf, \"tf_vectorizer.pkl\")  # Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41d66eb6-d39d-4e3e-952b-e1449d60e267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf_logistic_model.pkl']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the Logistic Regression model\n",
    "joblib.dump(tf_model, \"tf_logistic_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99244989-7318-4079-85c1-6c0f94f75d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: gensim in c:\\users\\91867\\appdata\\roaming\\python\\python311\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\91867\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\91867\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\91867\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (6.4.0)\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ad83b9c0-b9a2-4b1a-a9eb-bc7844882c06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.7955\n",
      "Precision on Test Data: 0.7924170616113744\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# Step 1: Tokenization function\n",
    "def tokenize_text(text):\n",
    "    # Tokenize, remove punctuation, and lower the case\n",
    "    tokens = text.lower().split()  # Simple whitespace split\n",
    "    return tokens\n",
    "\n",
    "# Step 2: Train Word2Vec model (CBOW or Skip-gram)\n",
    "model = Word2Vec(sentences=[tokenize_text(text) for text in X_train], vector_size=100, window=5, min_count=1, sg=0)  # sg=0 for CBOW\n",
    "\n",
    "# Save the model for later use\n",
    "model.save(\"word2vec_model\")\n",
    "\n",
    "# Step 3: Convert review to vector by averaging word vectors\n",
    "def review_to_vector(review, model):\n",
    "    tokens = tokenize_text(review)\n",
    "    vector = np.zeros(model.vector_size)  # Initialize with zeros\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        if word in model.wv:  # Only consider words present in the Word2Vec model\n",
    "            vector += model.wv[word]  # Add word vector to the total\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        vector /= count  # Average the word vectors\n",
    "    return vector\n",
    "\n",
    "# Step 4: Convert training and test data to Word2Vec vectors\n",
    "train_vectors = [review_to_vector(review, model) for review in X_train]\n",
    "test_vectors = [review_to_vector(review, model) for review in X_test]\n",
    "\n",
    "# Step 5: Train a Logistic Regression model on the Word2Vec vectors\n",
    "logistic = LogisticRegression(max_iter=1000)\n",
    "logistic.fit(train_vectors, y_train)\n",
    "\n",
    "# Step 6: Predict on the test data\n",
    "y_pred = logistic.predict(test_vectors)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "print(\"Accuracy on Test Data:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision on Test Data:\", precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "da4ac2e9-25b3-4b34-99a2-543840e4fde4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Accuracy: 0.6975\n",
      "GaussianNB Precision: 0.7010506208213945\n",
      "BernoulliNB Accuracy: 0.6775\n",
      "BernoulliNB Precision: 0.6945863125638406\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train Naive Bayes models (MultinomialNB, GaussianNB, BernoulliNB)\n",
    "\n",
    "# GaussianNB (assumes normal distribution for continuous features)\n",
    "# GaussianNB works directly on continuous features, so it might not perform well with sparse data like text data, but we include it for completeness\n",
    "gaussian_nb_model = GaussianNB()\n",
    "gaussian_nb_model.fit(train_vectors, y_train)\n",
    "gaussian_y_pred = gaussian_nb_model.predict(test_vectors)\n",
    "print(\"GaussianNB Accuracy:\", accuracy_score(y_test, gaussian_y_pred))\n",
    "print(\"GaussianNB Precision:\", precision_score(y_test, gaussian_y_pred))\n",
    "\n",
    "# BernoulliNB (suitable for binary features)\n",
    "bernoulli_nb_model = BernoulliNB()\n",
    "bernoulli_nb_model.fit(train_vectors, y_train)\n",
    "bernoulli_y_pred = bernoulli_nb_model.predict(test_vectors)\n",
    "print(\"BernoulliNB Accuracy:\", accuracy_score(y_test, bernoulli_y_pred))\n",
    "print(\"BernoulliNB Precision:\", precision_score(y_test, bernoulli_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de0ff4-204d-4f6a-936e-0ee7d569aa41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de444c8-bb8e-47d2-8f55-35c38f3d370e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
